# MLOPs â€“ Production-Ready Machine Learning Project (Visa Approval Prediction)

This repository demonstrates how to build an **end-to-end ML system** that loads and cleans data, trains models, monitors performance, and deploys to production using **Docker + AWS (ECR + EC2) + GitHub Actions**.  

---

## ğŸ”— Quick Links
- **Anaconda:** [Download](https://www.anaconda.com/)  
- **VS Code:** [Download](https://code.visualstudio.com/download)  
- **Git:** [Download](https://git-scm.com/)  
- **Flowchart Design Tool:** [Whimsical](https://whimsical.com/)  
- **Monitoring Tool:** [EvidentlyAI](https://www.evidentlyai.com/)  
- **MongoDB Atlas:** [Login](https://account.mongodb.com/account/login)  
- **Dataset (EasyVisa):** [Kaggle Link](https://www.kaggle.com/datasets/moro23/easyvisa-dataset)  

> **Dataset:** We are using the **EasyVisa dataset** from Kaggle. Download it and place it inside `data/raw/`.

---

## ğŸ§­ Table of Contents
1. Project Goals  
2. Tech Stack  
3. Project Structure  
4. Workflow (Code Flow)  
5. Local Setup  
6. Get the Data  
7. Environment Variables  
8. Train & Run Locally  
9. Monitoring with EvidentlyAI  
10. Dockerization  
11. AWS CICD (GitHub Actions â†’ ECR â†’ EC2)  
12. Git Commands  
13. License  

---

## ğŸ¯ Project Goals
- Build a machine learning pipeline for **Visa Approval Prediction**.  
- Follow **production-ready best practices**: modular code, configs, logging, exception handling.  
- Implement **data & model monitoring** using EvidentlyAI.  
- Automate **deployment with AWS (ECR + EC2) & GitHub Actions**.  

---

## ğŸ›  Tech Stack
- **Language:** Python 3.8  
- **ML/DS:** pandas, numpy, scikit-learn  
- **Monitoring:** EvidentlyAI  
- **Database:** MongoDB Atlas  
- **Packaging/Environment:** Conda, pip  
- **Containerization:** Docker  
- **Cloud:** AWS ECR (image registry), AWS EC2 (compute)  
- **CI/CD:** GitHub Actions  

---

## ğŸ“‚ Project Structure
```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ constants/           # Global constants
â”‚   â”œâ”€â”€ entity/              # Config & artifact schemas
â”‚   â”œâ”€â”€ components/          # Data ingestion, transformation, training, evaluation
â”‚   â”œâ”€â”€ pipeline/            # Orchestration pipelines
â”‚   â”œâ”€â”€ utils/               # Helpers: logging, IO, exceptions
â”‚   â””â”€â”€ app.py               # API/UI for predictions
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Raw Kaggle data
â”‚   â”œâ”€â”€ processed/           # Cleaned data
â”‚   â””â”€â”€ artifacts/           # Models, metrics
â”œâ”€â”€ reports/                 # Evidently reports
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .github/workflows/deploy.yml
â””â”€â”€ README.md
```

---

## ğŸ”„ Workflow (Code Flow)
1. **constants/** â†’ fixed values (paths, file names, seeds).  
2. **entity/** â†’ configs and artifact schemas.  
3. **components/** â†’  
   - Data Ingestion  
   - Data Transformation  
   - Model Training  
   - Model Evaluation  
4. **pipeline/** â†’ orchestrates the steps end-to-end.  
5. **app.py** â†’ API or UI for inference.  

---

## ğŸ’» Local Setup
```bash
# Create and activate Conda environment
conda create -n visa python=3.8 -y
conda activate visa

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ“Š Get the Data
**Option A (Manual):**  
1. Download dataset from [Kaggle EasyVisa](https://www.kaggle.com/datasets/moro23/easyvisa-dataset).  
2. Place it in `data/raw/`.  

**Option B (CLI):**
```bash
kaggle datasets download -d moro23/easyvisa-dataset -p data/raw --unzip
```

---

## âš™ï¸ Environment Variables
Set these before running:
```bash
export MONGODB_URL="mongodb+srv://<username>:<password>@<cluster-url>/<db>"
export AWS_ACCESS_KEY_ID=<your-key>
export AWS_SECRET_ACCESS_KEY=<your-secret>
export AWS_DEFAULT_REGION=us-east-1
```

---

## â–¶ï¸ Train & Run Locally
```bash
# Run pipeline
python main.py

# Run API
python src/app.py
```

---

## ğŸ“ˆ Monitoring with EvidentlyAI
- Use **EvidentlyAI** to track data drift and model quality.  
- Reports will be saved in `reports/`.  

---

## ğŸ³ Dockerization
```bash
# Build image
docker build -t visa-app .

# Run container
docker run -p 8080:8080 visa-app
```

---

## â˜ï¸ AWS CICD (GitHub Actions â†’ ECR â†’ EC2)
1. Create an **IAM User** with:  
   - `AmazonEC2ContainerRegistryFullAccess`  
   - `AmazonEC2FullAccess`  
2. Create **ECR Repository** â†’ save URI (e.g., `315865595366.dkr.ecr.us-east-1.amazonaws.com/visarepo`).  
3. Launch an **EC2 Instance (Ubuntu)**.  
4. Install Docker:  
   ```bash
   sudo apt-get update -y
   sudo apt-get upgrade -y
   curl -fsSL https://get.docker.com -o get-docker.sh
   sudo sh get-docker.sh
   sudo usermod -aG docker ubuntu
   newgrp docker
   ```
5. Configure EC2 as **GitHub self-hosted runner**.  
6. Add GitHub secrets:  
   - `AWS_ACCESS_KEY_ID`  
   - `AWS_SECRET_ACCESS_KEY`  
   - `AWS_DEFAULT_REGION`  
   - `ECR_REPO`  

---

## ğŸ”‘ Git Commands
```bash
git add .
git commit -m "Updated"
git push origin main
```

--